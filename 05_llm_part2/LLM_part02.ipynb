{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1tOS7oWba4s"
   },
   "source": [
    "# Large language models (LLMs): Part II\n",
    "\n",
    "Author: Archit Vasan , including materials on LLMs by Varuni Sastri, and discussion/editorial work by Taylor Childers, Carlo Graziani, Bethany Lusch, and Venkat Vishwanath (Argonne)\n",
    "\n",
    "Inspiration from the blog posts \"The Illustrated Transformer\" and \"The Illustrated GPT2\" by Jay Alammar, highly recommended reading.\n",
    "\n",
    "Before you begin, make sure that you have your environment set up and your repo refreshed, as described in previous lessons, and reviewed in the accompanying 'Readme.md' file. Make sure that you select the kernel 'datascience/conda-2023-01-10' at the top-left of the Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "1. Training and inference using Hugging Face\n",
    "2. Elements of an LLM\n",
    "3. Attention mechanisms\n",
    "4. Positional encoding\n",
    "5. Output layers\n",
    "6. Training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"HTTP_PROXY\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "# os.environ[\"HTTPS_PROXY\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "# os.environ[\"http_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "# os.environ[\"https_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "# os.environ[\"ftp_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM training and inference using HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/hf-logo-with-title.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "HuggingFace is a platform and community that provides open-source library tools and resources like pre-trained models and datasets.\n",
    "Refer to the following links for more information :\n",
    "\n",
    "https://huggingface.co/docs/hub/index\n",
    "\n",
    "https://huggingface.co/docs/transformers/en/index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: _Large Language Models are only as good as their training data. They have no ethics, no judgement, or editing ability. We will be using some pretrained models from Hugging Face which used wide samples of internet hosted text. The datasets have not been strictly filtered to restrict all malign content so the generated text may be surprisingly dark or questionable. They do not reflect our core values and are only used for demonstration purposes._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "We can use the Huggingface pipeline with a pretrained GPT2 model to generate text given a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/rainli/miniconda3/lib/python3.8/site-packages (24.0)\n",
      "Requirement already satisfied: transformers[torch] in /home/rainli/miniconda3/lib/python3.8/site-packages (4.39.3)\n",
      "Requirement already satisfied: filelock in /home/rainli/miniconda3/lib/python3.8/site-packages (from transformers[torch]) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/rainli/miniconda3/lib/python3.8/site-packages (from transformers[torch]) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/rainli/miniconda3/lib/python3.8/site-packages (from transformers[torch]) (1.21.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/rainli/miniconda3/lib/python3.8/site-packages (from transformers[torch]) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/rainli/miniconda3/lib/python3.8/site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/rainli/miniconda3/lib/python3.8/site-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/rainli/miniconda3/lib/python3.8/site-packages (from transformers[torch]) (2.27.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/rainli/miniconda3/lib/python3.8/site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/rainli/miniconda3/lib/python3.8/site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/rainli/miniconda3/lib/python3.8/site-packages (from transformers[torch]) (4.63.0)\n",
      "Requirement already satisfied: torch in /home/rainli/miniconda3/lib/python3.8/site-packages (from transformers[torch]) (2.2.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/rainli/miniconda3/lib/python3.8/site-packages (from transformers[torch]) (0.29.2)\n",
      "Requirement already satisfied: psutil in /home/rainli/miniconda3/lib/python3.8/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/rainli/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/rainli/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/rainli/miniconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers[torch]) (3.0.4)\n",
      "Requirement already satisfied: sympy in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch->transformers[torch]) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch->transformers[torch]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch->transformers[torch]) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch->transformers[torch]) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/rainli/miniconda3/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/rainli/miniconda3/lib/python3.8/site-packages (from requests->transformers[torch]) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rainli/miniconda3/lib/python3.8/site-packages (from requests->transformers[torch]) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/rainli/miniconda3/lib/python3.8/site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rainli/miniconda3/lib/python3.8/site-packages (from requests->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rainli/miniconda3/lib/python3.8/site-packages (from jinja2->torch->transformers[torch]) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/rainli/miniconda3/lib/python3.8/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'My dog really wanted to be with me. This had been a nightmare. He was trying to convince'},\n",
       " {'generated_text': 'My dog really wanted to be a dog,\" says Chris, his head bowed in his hands when he'},\n",
       " {'generated_text': 'My dog really wanted to be a bit more involved, and I really liked how she treated me.\"'},\n",
       " {'generated_text': 'My dog really wanted to talk about it to me, but it started talking about how I was never'},\n",
       " {'generated_text': 'My dog really wanted to do that. His tail is in all sorts of different colors – it was'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install transformers[torch]\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM, AutoConfig\n",
    "input_text = \"My dog really wanted to\"\n",
    "from transformers import pipeline\n",
    "generator = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\n",
    "generator(input_text, max_length=20, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will cover  evaluation metrics,as well as safe and responsibilities practices when using LLMs in **Session 8**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load in our own dataset and train a model with this data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/rainli/miniconda3/lib/python3.8/site-packages (0.29.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/rainli/miniconda3/lib/python3.8/site-packages (from accelerate) (1.21.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/rainli/miniconda3/lib/python3.8/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /home/rainli/miniconda3/lib/python3.8/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/rainli/miniconda3/lib/python3.8/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/rainli/miniconda3/lib/python3.8/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub in /home/rainli/miniconda3/lib/python3.8/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/rainli/miniconda3/lib/python3.8/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/rainli/miniconda3/lib/python3.8/site-packages (from packaging>=20.0->accelerate) (3.0.4)\n",
      "Requirement already satisfied: filelock in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/rainli/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/rainli/miniconda3/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: requests in /home/rainli/miniconda3/lib/python3.8/site-packages (from huggingface-hub->accelerate) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/rainli/miniconda3/lib/python3.8/site-packages (from huggingface-hub->accelerate) (4.63.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rainli/miniconda3/lib/python3.8/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/rainli/miniconda3/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rainli/miniconda3/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/rainli/miniconda3/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rainli/miniconda3/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (3.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/rainli/miniconda3/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "\n",
    "def load_dataset(train_path,test_path,tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128) \n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)   \n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset,test_dataset,data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rainli/miniconda3/lib/python3.8/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "/home/rainli/miniconda3/lib/python3.8/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "train_dataset,test_dataset,data_collator = load_dataset('dataset/train_input.txt','dataset/test_input.txt', tokenizer)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=3, # number of training epochs\n",
    "    per_device_train_batch_size=32, # batch size for training\n",
    "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
    "    eval_steps = 40, # Number of update steps between two evaluations.\n",
    "    save_steps=80, # after # steps model is saved \n",
    "    warmup_steps=50,# number of warmup steps for learning rate scheduler\n",
    "    prediction_loss_only=True,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is going on below the hood?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two components that are \"black-boxes\" here:\n",
    "1. The method for tokenization\n",
    "2. The model that generates novel text.\n",
    "\n",
    "Carlo Graziani already gave a great explanation of tokenization last week and how this affects embeddings (https://github.com/argonne-lcf/ai-science-training-series/blob/main/04_intro_to_llms/Sequential_Data_Models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will take a closer look at how the model is designed to deal with language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look inside GPT2! GPT2 incorporates the `GPT2LMHeadModel` architecture so let's inspect this more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "gpt2 does not appear to have a file named config.json. Checkout 'https://huggingface.co/gpt2/tree/main' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2Tokenizer, GPT2LMHeadModel\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGPT2LMHeadModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/modeling_utils.py:3006\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   3005\u001b[0m     config_path \u001b[38;5;241m=\u001b[39m config \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[0;32m-> 3006\u001b[0m     config, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3016\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3017\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_from_auto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_auto_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_from_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3019\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3020\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3021\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3022\u001b[0m     \u001b[38;5;66;03m# In case one passes a config to `from_pretrained` + \"attn_implementation\"\u001b[39;00m\n\u001b[1;32m   3023\u001b[0m     \u001b[38;5;66;03m# override the `_attn_implementation` attribute to `attn_implementation` of the kwargs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[38;5;66;03m# we pop attn_implementation from the kwargs but this handles the case where users\u001b[39;00m\n\u001b[1;32m   3028\u001b[0m     \u001b[38;5;66;03m# passes manually the config to `from_pretrained`.\u001b[39;00m\n\u001b[1;32m   3029\u001b[0m     config \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/configuration_utils.py:602\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m revision\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_set_token_in_kwargs(kwargs, token)\n\u001b[0;32m--> 602\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[1;32m    604\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using a model of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to instantiate a model of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    607\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/configuration_utils.py:631\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    633\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/configuration_utils.py:686\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    682\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/utils/hub.py:369\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(resolved_file):\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[0;32m--> 369\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Checkout \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tree/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         )\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: gpt2 does not appear to have a file named config.json. Checkout 'https://huggingface.co/gpt2/tree/main' for available files."
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General elements of an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2 is an example of the popular Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cig2mvfguetQ"
   },
   "source": [
    "<img src=\"images/decoder_only_block.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "Image credit: https://arxiv.org/pdf/1706.03762.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gray section in this figure is the Transfomer Decoder and it is the main mechanism GPT2 uses to encode context of language into its predictions.\n",
    "\n",
    "<img src=\"images/transformer-decoder-intro.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "Image credit: https://jalammar.github.io/illustrated-gpt2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Transformer-Decoder is composed of Decoder blocks stacked ontop of each other where each contains two types of layers: \n",
    "1. Masked Self-Attention and \n",
    "2. Feed Forward Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have already discussed Feed Forward Neural Networks in detail in the other lectures in this series. To review this, please look at https://github.com/argonne-lcf/ai-science-training-series/blob/main/02_intro_neural_networks/01_introduction_mnist.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we will \n",
    "* First, discuss attention mechanisms at length as this is arguably the greatest contribution by Transformers.\n",
    "* Second, extend the discussion from last week (https://github.com/argonne-lcf/ai-science-training-series/blob/main/04_intro_to_llms/Sequential_Data_Models.ipynb) on embedding input data while taking into account position.\n",
    "* Third, discuss outputting real text/sequences from the models.\n",
    "* Fourth, build a training loop for a mini-LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's set up all the imports we will need**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3d696fb570>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IMPORTS\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4 ## so head_size = 16\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BowLYFlCrDrr"
   },
   "source": [
    "## Attention mechanisms\n",
    "\n",
    "Suppose the following sentence is an input sentence we want to translate using an LLM:\n",
    "\n",
    "`”The animal didn't cross the street because it was too tired”`\n",
    "\n",
    "Last week, Carlo mentioned that the Transformer learns an embedding of all words allowing interpretation of meanings of words.\n",
    "\n",
    "<img src=\"images/viz-bert-voc-verbs.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "So, if the model did a good job in token embedding, it will \"know\" what all the words in this sentence mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to understand a full sentence, the model also need to understand what each word means in relation to other words.\n",
    "\n",
    "For example, when we read the sentence:\n",
    "`”The animal didn't cross the street because it was too tired”`\n",
    "we know intuitively that the word `\"it\"` refers to `\"animal\"`, the state for `\"it\"` is `\"tired\"`, and the associated action is `\"didn't cross\"`.\n",
    "\n",
    "However, the model needs a way to learn all of this information in a simple yet generalizable way.\n",
    "What makes Transformers particularly powerful compared to earlier sequential architectures is how it encodes context with the **self-attention mechanism**.\n",
    "\n",
    "As the model processes each word in the input sequence, attention looks at other positions in the input sequence for clues to a better understanding for this word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer_self-attention_visualization.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGbAi0cJ7x3a"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-attention mechanisms use 3 vectors to encode the context of a word in a sequence with another word:\n",
    "1. Query: the word representation we score other words against using the other word's keys\n",
    "2. Key: labels for the words in a sequence that we match against the query\n",
    "3. Value: actual word representation. We will use the queries and keys to score the word's relevance to the query, and multiply this by the value. \n",
    "\n",
    "An analogy provided by Jay Alammar is thinking about attention as choosing a file from a file cabinet according to information on a post-it note. You can use the post-it note (query) to identify the folder (key) that most matches the topic you are looking up. Then you access the contents of the file (value) according to its relevance to your query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/self-attention-example-folders-3.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "Image credit: https://jalammar.github.io/illustrated-gpt2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our models, we can encode queries, keys, and values using simple linear layers with the same size (`sequence length, head_size`). During the training process, these layers will be updated to best encode context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 32 # channels\n",
    "head_size = 16\n",
    "\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jzf9VE_AqWeR"
   },
   "source": [
    "The algorithm for self-attention is as follows:\n",
    "\n",
    "1. Generate query, key and value vectors for each word\n",
    "2. Calculate a score for each word in the input sentence against each other.\n",
    "3. Divide the scores by the square root of the dimension of the key vectors to stabilize the gradients. This is then passed through a softmax operation.\n",
    "4. Multiply each value vector by the softmax score.\n",
    "5. Sum up the weighted value vectors to produce the output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/self-attention-output.png\" alt=\"Drawing\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOwm-NkXA8U3"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how attention is performed in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# Here we want the wei to be data dependent - ie gather info from the past but in a data dependant way\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16) # each token here (totally B*T) produce a key and query in parallel and independently\n",
    "q = query(x) # (B, T, 16)\n",
    "v = value(x)\n",
    "\n",
    "wei =  q @ k.transpose(-2, -1) * head_size**-0.5 # (B, T, 16) @ (B, 16, T) ---> (B, T, T). #\n",
    "wei = F.softmax(wei, dim=-1) # exponentiate and normalize giving a nice distibution that sums to 1 and\n",
    "                             # now it tells us that in a data dependent manner how much of info to aggregate from\n",
    "\n",
    "out = wei @ v # aggregate the attention scores and value vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lwyFlxKW6oA"
   },
   "source": [
    "### Multi-head attention\n",
    "\n",
    "In practice, multiple attention heads are used which\n",
    "1. Expands the model’s ability to focus on different positions and prevent the attention to be dominated by the word itself.\n",
    "2. Have multiple “representation subspaces”. Have multiple sets of Query/Key/Value weight matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer_multi-headed_self-attention-recap.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oHsezdVBIaf"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see attention mechanisms in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the powerful visualization tool bertviz, which allows an interactive experience of the attention mechanisms. Normally these mechanisms are abstracted away but this will allow us to inspect our model in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install bertviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the model, GPT2 and look at the attention mechanisms. \n",
    "\n",
    "**Hint... click on the different blocks in the visualization to see the attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, utils, AutoModelForCausalLM\n",
    "\n",
    "from bertviz import model_view\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "\n",
    "model_name = 'openai-community/gpt2'\n",
    "input_text = \"No, I am your father\"  \n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "inputs = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
    "outputs = model(inputs)  # Run model\n",
    "attention = outputs[-1]  # Retrieve attention from model outputs\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings\n",
    "model_view(attention, tokens)  # Display model view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFq78-kjbrWp"
   },
   "source": [
    "Last week, Carlo discussed token embedding, which is when words are encoded into a vocabulary. Now, we just discussed attention mechanisms which account for context between words. Another question we should ask is how do we account for the order of words in an input sentence\n",
    "\n",
    "Consider the following two sentences to see why this is important:\n",
    "\n",
    "``The man ate the sandwich.``\n",
    "\n",
    "``The sandwich ate the man.``\n",
    "\n",
    "Clearly, these are two vastly different situations even though they have the same words. The Transformer can \n",
    "\n",
    "Transformers differentiate between these situations by adding a **Positional encoding** vector to each input embedding. These vectors follow a specific pattern that the model learns, which helps it determine the position of each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/positional_encoding.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "Image credit: https://medium.com/@xuer.chen.human/llm-study-notes-positional-encoding-0639a1002ec0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up positional encoding similarly as token embedding using the ``nn.Embedding`` tool. We use a simple embedding here but there are more complex positional encodings used such as sinusoidal. \n",
    "\n",
    "For an explanation of different positional encodings, refer to this post: https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 65\n",
    "n_embd = 64\n",
    "\n",
    "token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "position_embedding_table = nn.Embedding(block_size, n_embd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice the positional encoding size is `(block_size, n_embed)` because it encodes for the postion of a token within the sequence of size `block_size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the position embedding used is simply added to the token embedding to apply positional embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at token embedding alone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([1,3,15,4,7,1,4,9])\n",
    "x = token_embedding_table(x)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And token + positional embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,3,15,4,7,1,4,9])\n",
    "x= position_embedding_table(x) + token_embedding_table(x)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a clear offset between these two embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training process, these embeddings will be learned to best encode the token and positional embeddings of the sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iF1HzH9xNJ7S"
   },
   "source": [
    "## Output layers\n",
    "\n",
    "At the end of our Transformer model, we are left with a vector, so how do we turn this into a word?\n",
    "\n",
    "<img src=\"images/transformer-decoder-intro.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Using a final Linear layer and a Softmax Layer.\n",
    "The Linear layer projects the vector produced by the stack of decoders, into a larger vector called a logits vector.\n",
    "\n",
    "If our model knows 10,000 unique English words learned from its training dataset the logits vector is 10,000 cells wide – each cell corresponds to the score of a unique word.\n",
    "\n",
    "The softmax layer turns those scores into probabilities. The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer_decoder_output_softmax.png\" alt=\"Drawing\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS6r-z8dN_RV"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XK8q67P03yr4"
   },
   "source": [
    "## Training\n",
    "\n",
    "How does an LLM improve over time?\n",
    "We want to compare the probabilitiy distribution for each token generated by our model to the ground truths. \n",
    "Our model produces a probability distribution for each token. We want to compare these probability distributions to the ground truths. \n",
    "For example, when translating the sentence: “je suis étudiant” into “i am a student” as can be seen in the example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/output_target_probability_distributions.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS6r-z8dN_RV"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can calculate the loss between the vector it generates and the ground truth vector seen in this example. A commonly used loss function is cross entropy loss:\n",
    "\n",
    "$CE = -\\sum_{x \\in X} p(x) log q(x)$\n",
    "\n",
    "where p(x) represents the true distribution and q(x) represents the predicted distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "logits = torch.tensor([0.5, 0.1, 0.3])\n",
    "targets = torch.tensor([1.0, 0.0, 0.0])\n",
    "loss = F.cross_entropy(logits, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important metric commonly used in LLMs is **perplexity**.\n",
    "\n",
    "Intuitively, perplexity means to be surprised. We measure how much the model is surprised by seeing new data. The lower the perplexity, the better the training is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, perplexity is just the exponent of the negative cross entropy loss:\n",
    "\n",
    "$\\text{perplexity} = exp(\\text{CE})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are using cross entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train a mini-LLM from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "# hyperparameters\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 10\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4 ## so head_size = 16\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data and create train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to be using the tiny Shakespeare dataset. \n",
    "Data is tokenized according to a simple character based tokenizer.\n",
    "Data is split into a train and test set so we have something to test after performing training (9:1 split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the components of the Decoder block: \n",
    "* MultiHeadAttention\n",
    "* FeedForward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C) 16,32,16\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd), # Projection layer going back into the residual pathway\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine components into the Decoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))    # Communication\n",
    "        x = x + self.ffwd(self.ln2(x))  # Computation\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the full Transformer model \n",
    "This is a combination of the Token embeddings, Positional embeddings, a stack of Transformer blocks and an output block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super simple language model\n",
    "class LanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be training a larger LLM on distributed resources in session 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "1. In this notebook, we learned the various components of an LLM. \n",
    "    Your homework this week is to take the mini LLM we created from scratch and run your own training loop. Show how the training and validation perplexity change over the steps.\n",
    "      \n",
    "    Hint: this function might be useful for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': tensor(29.5673), 'val': tensor(27.6491)}\n",
      "{'train': tensor(21.6226), 'val': tensor(19.1765)}\n",
      "{'train': tensor(15.6167), 'val': tensor(14.1617)}\n",
      "{'train': tensor(14.8840), 'val': tensor(13.5222)}\n",
      "{'train': tensor(13.7349), 'val': tensor(12.7169)}\n",
      "{'train': tensor(12.6068), 'val': tensor(13.0489)}\n",
      "{'train': tensor(12.8858), 'val': tensor(11.7164)}\n",
      "{'train': tensor(11.9753), 'val': tensor(11.8765)}\n",
      "{'train': tensor(11.7977), 'val': tensor(10.9782)}\n",
      "{'train': tensor(11.7059), 'val': tensor(10.9833)}\n",
      "{'train': tensor(11.2319), 'val': tensor(10.4806)}\n",
      "{'train': tensor(11.1517), 'val': tensor(10.0190)}\n",
      "{'train': tensor(10.9033), 'val': tensor(10.3569)}\n",
      "{'train': tensor(10.3611), 'val': tensor(10.1619)}\n",
      "{'train': tensor(10.3392), 'val': tensor(10.2225)}\n",
      "{'train': tensor(10.2421), 'val': tensor(9.9099)}\n",
      "{'train': tensor(9.9258), 'val': tensor(9.8020)}\n",
      "{'train': tensor(10.0697), 'val': tensor(9.5042)}\n",
      "{'train': tensor(9.9456), 'val': tensor(9.4202)}\n",
      "{'train': tensor(9.9262), 'val': tensor(9.8009)}\n",
      "{'train': tensor(9.6760), 'val': tensor(9.4084)}\n",
      "{'train': tensor(9.9237), 'val': tensor(8.9980)}\n",
      "{'train': tensor(9.4579), 'val': tensor(8.6773)}\n",
      "{'train': tensor(9.2185), 'val': tensor(8.6966)}\n",
      "{'train': tensor(8.9661), 'val': tensor(8.6276)}\n",
      "{'train': tensor(9.2375), 'val': tensor(8.3375)}\n",
      "{'train': tensor(8.8495), 'val': tensor(8.4555)}\n",
      "{'train': tensor(9.1122), 'val': tensor(8.6336)}\n",
      "{'train': tensor(9.2100), 'val': tensor(8.1572)}\n",
      "{'train': tensor(8.4869), 'val': tensor(8.2859)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "model = LanguageModel().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "eval_iters = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_one_epoch(model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for batch in range(eval_iters):\n",
    "        X, y = get_batch('train')\n",
    "        \n",
    "        # resets the gradients \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        pred = model(X)\n",
    "        pred = pred[0]\n",
    "        # print(pred[0])\n",
    "        # print(y)\n",
    "        loss = loss_fn(pred.view(-1, pred.size(-1)), y.view(-1))\n",
    "        \n",
    "        # backward pass calculates gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # take one step with these gradients\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            losses[k] = loss.item()\n",
    "            perplexity = torch.exp(loss)\n",
    "            #print(split, perplexity)\n",
    "        out[split] = torch.exp(losses.mean())\n",
    "    model.train()\n",
    "    \n",
    "    return out\n",
    "\n",
    "n_epoch = 30\n",
    "for i in range(n_epoch):\n",
    "    with torch.enable_grad():\n",
    "        train_one_epoch(model, loss_fn, optimizer)\n",
    "        print(estimate_loss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perplexity decreases with steps of the optimization.\n",
    "\n",
    "\n",
    "\n",
    "2. Run the same training loop but modify one of the hyperparameters from this list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# hyperparameters\n",
    "n_embd = 64\n",
    "n_head = 4 ## so head_size = 16\n",
    "n_layer = 2\n",
    "\n",
    "n_epoch = 30\n",
    "x = range(n_epoch)\n",
    "y1 = torch.zeros(n_epoch)\n",
    "for i in range(n_epoch):\n",
    "    with torch.enable_grad():\n",
    "        train_one_epoch(model, loss_fn, optimizer)\n",
    "        y1[i] = estimate_loss()['train'].item()\n",
    "        \n",
    "n_layer = 4\n",
    "y2 = torch.zeros(n_epoch)\n",
    "for i in range(n_epoch):\n",
    "    with torch.enable_grad():\n",
    "        train_one_epoch(model, loss_fn, optimizer)\n",
    "        y2[i] = estimate_loss()['train'].item()\n",
    "        \n",
    "        \n",
    "n_layer = 8\n",
    "y3 = torch.zeros(n_epoch)\n",
    "for i in range(n_epoch):\n",
    "    with torch.enable_grad():\n",
    "        train_one_epoch(model, loss_fn, optimizer)\n",
    "        y3[i] = estimate_loss()['train'].item()\n",
    "\n",
    "        \n",
    "n_layer = 16\n",
    "y4 = torch.zeros(n_epoch)\n",
    "for i in range(n_epoch):\n",
    "    with torch.enable_grad():\n",
    "        train_one_epoch(model, loss_fn, optimizer)\n",
    "        y4[i] = estimate_loss()['train'].item()\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot each trend line\n",
    "ax.plot(x, y1, label='n_layer = 2')\n",
    "ax.plot(x, y2, label='n_layer = 4')\n",
    "ax.plot(x, y3, label='n_layer = 8')\n",
    "ax.plot(x, y4, label='n_layer = 16')\n",
    "\n",
    "# Add labels, title, legend, etc.\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('perplexity')\n",
    "ax.set_title('Number of Layers')\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this at least 4 times with a different value and plot each perplexity over training step. Write a sentence on how the perplexity changed.\n",
    "\n",
    "With more layers, the perplexity decreases in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus 1: output some generated text from each model you trained. Did the output make more sense with some hyperparameters than others? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus 2: We saw a cool visualization of attention mechanisms with BertViz. Take a more complicated model than GPT2 such as \"meta-llama/Llama-2-7b-chat-hf\" and see how the attention mechanisms are different "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDXLTusqxXHf"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some recommendations for further reading and additional code for review.\n",
    "\n",
    "* \"The Illustrated Transformer\" by Jay Alammar\n",
    "* \"Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)\"\n",
    "* \"The Illustrated GPT-2 (Visualizing Transformer Language Models)\"\n",
    "* \"A gentle introduction to positional encoding\"\n",
    "* \"LLM Tutorial Workshop (Argonne National Laboratory)\"\n",
    "* \"LLM Tutorial Workshop Part 2 (Argonne National Laboratory)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
